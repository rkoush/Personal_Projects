{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdf182c",
   "metadata": {},
   "source": [
    "\n",
    "# Customer Segmentation with **API-only** Data (No CSVs)\n",
    "\n",
    "**Source API:** DummyJSON — `/users` and `/carts`\n",
    "\n",
    "**Plan**\n",
    "1. Fetch data via HTTP (requests), in-memory only\n",
    "2. Feature engineer customer-level metrics (frequency, spend, basket metrics, discount behavior, product diversity)\n",
    "3. PCA for multivariate exploration\n",
    "4. KMeans & GMM clustering\n",
    "5. Hyperparameter tuning: Silhouette, Davies–Bouldin, BIC\n",
    "6. Cluster profiling + optional heuristic names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837795c",
   "metadata": {},
   "source": [
    "\n",
    "## 0) Setup & API Fetch (in-memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac6d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "BASE = \"https://dummyjson.com\"\n",
    "\n",
    "def fetch_all(endpoint, page_size=100, key=None):\n",
    "    url = BASE + endpoint\n",
    "    r0 = requests.get(url, params={\"limit\": 1, \"skip\": 0})\n",
    "    r0.raise_for_status()\n",
    "    data0 = r0.json()\n",
    "    if key is None:\n",
    "        key = [k for k,v in data0.items() if isinstance(v, list)][0]\n",
    "    total = data0.get(\"total\", len(data0.get(key, [])))\n",
    "    pages = math.ceil(total / page_size)\n",
    "    items = []\n",
    "    for p in range(pages):\n",
    "        r = requests.get(url, params={\"limit\": page_size, \"skip\": p*page_size})\n",
    "        r.raise_for_status()\n",
    "        j = r.json()\n",
    "        items.extend(j.get(key, []))\n",
    "    return items\n",
    "\n",
    "users_raw = fetch_all(\"/users\", key=\"users\")\n",
    "carts_raw = fetch_all(\"/carts\", key=\"carts\")\n",
    "\n",
    "users = pd.json_normalize(users_raw)\n",
    "carts = pd.json_normalize(carts_raw, sep=\"_\")\n",
    "\n",
    "users.shape, carts.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e227f9",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Feature Engineering (Customer-level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cart-level features\n",
    "carts[\"avg_item_price\"] = carts[\"total\"] / carts[\"totalQuantity\"]\n",
    "carts[\"discount_rate\"] = 1 - (carts[\"discountedTotal\"] / carts[\"total\"]).replace(0, np.nan)\n",
    "\n",
    "def unique_product_ids(prod_list):\n",
    "    try:\n",
    "        return len({p.get(\"id\") for p in prod_list})\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "carts[\"n_unique_products\"] = carts[\"products\"].apply(unique_product_ids)\n",
    "\n",
    "cust = carts.groupby(\"userId\").agg(\n",
    "    n_orders=(\"id\", \"nunique\"),\n",
    "    total_spend=(\"total\", \"sum\"),\n",
    "    total_spend_discounted=(\"discountedTotal\", \"sum\"),\n",
    "    mean_total=(\"total\", \"mean\"),\n",
    "    mean_discounted_total=(\"discountedTotal\", \"mean\"),\n",
    "    mean_total_products=(\"totalProducts\", \"mean\"),\n",
    "    mean_total_qty=(\"totalQuantity\", \"mean\"),\n",
    "    mean_unique_products=(\"n_unique_products\", \"mean\"),\n",
    "    mean_avg_item_price=(\"avg_item_price\", \"mean\"),\n",
    "    mean_discount_rate=(\"discount_rate\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "demo_cols = [\n",
    "    \"id\",\"age\",\"gender\",\"email\",\"phone\",\n",
    "    \"address.city\",\"address.state\",\"address.country\"\n",
    "]\n",
    "users_ = users[demo_cols].rename(columns={\n",
    "    \"id\":\"userId\",\n",
    "    \"address.city\":\"address_city\",\n",
    "    \"address.state\":\"address_state\",\n",
    "    \"address.country\":\"address_country\"\n",
    "})\n",
    "cust = cust.merge(users_, on=\"userId\", how=\"left\")\n",
    "\n",
    "cust[\"gender_enc\"] = cust[\"gender\"].map({\"male\":0, \"female\":1}).fillna(-1)\n",
    "\n",
    "top_countries = cust[\"address_country\"].value_counts().head(5).index.tolist()\n",
    "for c in top_countries:\n",
    "    cust[f\"country_{c}\"] = (cust[\"address_country\"] == c).astype(int)\n",
    "\n",
    "cust.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c26e80",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3fd10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_feats = [\n",
    "    \"n_orders\",\"total_spend\",\"total_spend_discounted\",\n",
    "    \"mean_total\",\"mean_discounted_total\",\n",
    "    \"mean_total_products\",\"mean_total_qty\",\n",
    "    \"mean_unique_products\",\"mean_avg_item_price\",\"mean_discount_rate\",\n",
    "    \"age\",\"gender_enc\"\n",
    "] + [c for c in cust.columns if c.startswith(\"country_\")]\n",
    "\n",
    "X = cust[num_feats].copy()\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "imp = SimpleImputer(strategy=\"median\")\n",
    "X_imp = imp.fit_transform(X)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imp)\n",
    "\n",
    "X.shape, len(num_feats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f097ff",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Multivariate Analysis (Correlation + PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddaacd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "corr = pd.DataFrame(X_imp, columns=num_feats).corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(corr, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(num_feats)), num_feats, rotation=75)\n",
    "plt.yticks(range(len(num_feats)), num_feats)\n",
    "plt.title(\"Feature Correlations\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], s=8, alpha=0.5)\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(\"PCA Scatter (PC1 vs PC2)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7555836",
   "metadata": {},
   "source": [
    "\n",
    "## 4) KMeans Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01af558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_range = range(2, 11)\n",
    "km_scores = []\n",
    "for k in k_range:\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    db  = davies_bouldin_score(X_scaled, labels)\n",
    "    km_scores.append({\"k\":k, \"silhouette\":sil, \"davies_bouldin\":db})\n",
    "\n",
    "km_df = pd.DataFrame(km_scores)\n",
    "display(km_df)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(km_df[\"k\"], km_df[\"silhouette\"], marker=\"o\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Silhouette\"); plt.title(\"KMeans: Silhouette vs k\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(km_df[\"k\"], km_df[\"davies_bouldin\"], marker=\"o\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Davies–Bouldin (lower better)\"); plt.title(\"KMeans: DB vs k\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198d543",
   "metadata": {},
   "source": [
    "\n",
    "### Fit Best KMeans (by Silhouette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_k = int(km_df.sort_values(\"silhouette\", ascending=False).iloc[0][\"k\"])\n",
    "best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92eaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "km = KMeans(n_clusters=best_k, n_init=10, random_state=42)\n",
    "km_labels = km.fit_predict(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=km_labels, s=10, alpha=0.7)\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(f\"KMeans (k={best_k}) on PCA\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bccf25",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Gaussian Mixture Model (GMM) + BIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b969aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "g_range = range(2, 11)\n",
    "gmm_scores = []\n",
    "for g in g_range:\n",
    "    gmm = GaussianMixture(n_components=g, covariance_type=\"full\", random_state=42)\n",
    "    gmm.fit(X_scaled)\n",
    "    labels = gmm.predict(X_scaled)\n",
    "    bic = gmm.bic(X_scaled)\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    gmm_scores.append({\"components\":g, \"BIC\":bic, \"silhouette\":sil})\n",
    "\n",
    "gmm_df = pd.DataFrame(gmm_scores)\n",
    "display(gmm_df.sort_values(\"BIC\"))\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(gmm_df[\"components\"], gmm_df[\"BIC\"], marker=\"o\")\n",
    "plt.xlabel(\"Components\"); plt.ylabel(\"BIC (lower better)\"); plt.title(\"GMM: BIC vs Components\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_g = int(gmm_df.sort_values(\"BIC\", ascending=True).iloc[0][\"components\"])\n",
    "best_g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b591ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gmm = GaussianMixture(n_components=best_g, covariance_type=\"full\", random_state=42)\n",
    "gmm_labels = gmm.fit_predict(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=gmm_labels, s=10, alpha=0.7)\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(f\"GMM (components={best_g}) on PCA\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48fbe04",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Cluster Profiling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profile_cols = list(num_feats)\n",
    "\n",
    "def profile(Ximp, labels, cols, name):\n",
    "    d = pd.DataFrame(Ximp, columns=cols).copy()\n",
    "    d[\"__label__\"] = labels\n",
    "    prof = d.groupby(\"__label__\")[cols].mean().round(2)\n",
    "    prof[\"n_customers\"] = d.groupby(\"__label__\").size()\n",
    "    print(f\"=== {name} profile ===\")\n",
    "    display(prof)\n",
    "    return prof\n",
    "\n",
    "km_profile = profile(X_imp, km_labels, profile_cols, \"KMeans\")\n",
    "gmm_profile = profile(X_imp, gmm_labels, profile_cols, \"GMM\")\n",
    "\n",
    "# Normalized line chart for KMeans\n",
    "norm = (km_profile[profile_cols] - km_profile[profile_cols].min()) / (km_profile[profile_cols].max() - km_profile[profile_cols].min())\n",
    "plt.figure(figsize=(10,5))\n",
    "for i, row in norm.iterrows():\n",
    "    plt.plot(range(len(profile_cols)), row.values, marker=\"o\", label=f\"Cluster {i}\")\n",
    "plt.xticks(range(len(profile_cols)), profile_cols, rotation=75)\n",
    "plt.title(\"KMeans Cluster Profiles (Normalized)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d89819",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Optional: Heuristic Segment Names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c9a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def name_clusters(profile_df):\n",
    "    labels = {}\n",
    "    med_spend = profile_df[\"total_spend\"].median() if \"total_spend\" in profile_df.columns else profile_df[\"mean_total\"].median()\n",
    "    med_freq  = profile_df[\"n_orders\"].median() if \"n_orders\" in profile_df.columns else  profile_df[\"mean_total_products\"].median()\n",
    "    for idx, row in profile_df.iterrows():\n",
    "        spend_level = row.get(\"total_spend\", row.get(\"mean_total\", 0))\n",
    "        freq_level  = row.get(\"n_orders\", row.get(\"mean_total_products\", 0))\n",
    "        if spend_level > med_spend and freq_level > med_freq:\n",
    "            labels[idx] = \"High-Value Frequent\"\n",
    "        elif spend_level > med_spend and freq_level <= med_freq:\n",
    "            labels[idx] = \"Big-Ticket Occasional\"\n",
    "        elif spend_level <= med_spend and freq_level > med_freq:\n",
    "            labels[idx] = \"Budget Loyal\"\n",
    "        else:\n",
    "            labels[idx] = \"Mid-Low Value\"\n",
    "    return labels\n",
    "\n",
    "km_names = name_clusters(km_profile)\n",
    "gm_names = name_clusters(gmm_profile)\n",
    "\n",
    "cust_out = cust.copy()\n",
    "cust_out[\"cluster_kmeans\"] = km_labels\n",
    "cust_out[\"segment_kmeans\"] = cust_out[\"cluster_kmeans\"].map(km_names)\n",
    "cust_out[\"cluster_gmm\"]    = gmm_labels\n",
    "cust_out[\"segment_gmm\"]    = cust_out[\"cluster_gmm\"].map(gm_names)\n",
    "\n",
    "cust_out[[\"userId\",\"age\",\"gender\",\"address_country\",\"n_orders\",\"total_spend\",\"segment_kmeans\",\"segment_gmm\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db05685",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Next Steps (No file writes)\n",
    "- Add category preference vectors (explode products and compute per-user TF-IDF on product titles)\n",
    "- Try UMAP before clustering\n",
    "- Check stability across seeds\n",
    "\n",
    "> If you *choose* to export later, uncomment:\n",
    "> ```python\n",
    "> # cust_out.to_csv(\"customer_segments_api.csv\", index=False)\n",
    "> ```\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
